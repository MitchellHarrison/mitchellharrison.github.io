{
  "hash": "34cdd52fe8362f7ee017ee72d9c7d9ee",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"The Bias-Variance Tradeoff | Mathematical Statistics 2\"\nauthor: \"Mitch Harrison\"\ncategories:\n  - \"Statistics\"\n  - \"Mathematical Statistics\"\nimage: \"../images/thumbnails/mathematical_statistics/2.png\"\n---\n\n\n\n\n# Loss\n\n[Last time](../tutorials/math_stat_1.qmd), we noted that we cannot precisely \ncalculate bias or variance since they are conditional on the parameter we are \nestimating in the first place. If we knew that value, we wouldn't need an \nestimator. Ideally, our estimators would be as close as possible to the true \nvalue of our unknown parameter $\\theta$, but there may be infinitely many \npossible values for $\\theta$. Instead, we will seek to be close to a *range* of \npossible values of $\\theta$.\n\n::: {.callout-important}\n### Definition\n**Closeness** describes how much we are willing to \"pay\" to be some \"distance\" \naway from the true value of $\\theta$. We will measure this distance with a \nfunction (called a **loss function**), which is denoted as:\n\n$$\n\\ell(\\theta, a).\n$$\nThis notation is somewhat confusing, because we are now using $a$ to denote our\nestimate instead of $\\hat{\\theta}$. So you can think of it as \n$\\ell(\\theta, \\hat{\\theta})$ if that is more helpful (as it is for me).\n:::\n\nAs an example, if we choose a loss function, \n\n$$\n\\ell(\\theta, \\hat{\\theta}) = (\\theta - \\hat{\\theta})^2,\n$$\nthen we have arrived at the *squared-error loss* function. Observe that the \ndifference between our guess and the true value is the error, and we are \nsquaring that value. If we take the mean of that function, we arrive at a \ncritical value in mathematical statistics that you may have heard of: \nthe **mean-squared error** (MSE).\n\n::: {.callout-important}\n### Definition\n**Risk** is the expected loss for a given loss function $\\ell$. Mathematically,\nit is denoted as\n$$\nR_{\\delta}(\\theta) = \\mathbb{E}_{X|\\theta}[\\ell(\\theta, \\delta(\\mathbf{X}))],\n$$\nwhere $\\delta(\\mathbf{X})$ is the function that gives us our estimator. In\neffect, the risk is the expected loss given some loss function \n$\\ell(\\theta,\\hat{\\theta})$.\n:::\n\nWe will get back to loss next time.\n\n# The Bias-Variance Tradeoff\n\n## Worked example: bias\n\nLet's work on our first example problem to nail some things down. Let our data \n$X_1, \\cdots, X_n \\sim N(\\mu, \\sigma^2)$, and let each data point be independent\nand identically distributed (iid). Like last time, $\\sigma^2$ is fixed and \nknown. We are interested in estimating $\\mu$. Recall our two estimators from \nthe previous article:\n\n$$\n\\begin{align*}\n\\delta_1(\\mathbf{X}) &= \\overline{X} \\\\\n\\delta_2(\\mathbf{X}) &= 5.\n\\end{align*}\n$$\n\nThe expected value of $\\delta_2$ is 5. Let's find the expected value of \n$\\delta_1$. Recall our generic formula for the expectation of an estimator is\n$\\mathbb{E}(\\delta(\\mathbf{X}) | \\theta)$ for some estimator $\\delta$ and true\nvalue $\\theta$. In this case, our estimator is $\\overline{X}$ and our parameter\nis $\\mu$. Thus:\n$$\n\\begin{align*}\n\\mathbb{E}(\\delta_1(\\mathbf{X})|\\theta) &= \\mathbb{E}(\\overline{X} | \\mu) \\\\\n&= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^nX_i}{n}\\right] \n& \\text{expanding out }\\overline{X} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mathbb{E}(X_i|\\mu)\n& \\text{expectation can be distributed into sums} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mu\n& \\text{because } \\mathbb{E}(X_i) = \\mu \\text{ for any }i\\\\\n&= \\frac{n\\mu}{n} \\\\\n&= \\mu\n\\end{align*}\n$$\n\nWe have a bias of zero! That means that the expected value of our estimator is \nprecisely equivalent to our unknown parameter. It feels like we have solved \nstatistics, right? Well... no. But we will get to that in a moment. For now, \nlet's visualize bias. \n\nLet's say that the true (but unknown to us) value of $\\mu$ is 1. One of our \nestimators was the constant 5. If we let 5 be our guess for the mean, we are \nsaying, \"I think the distribution is centered on 5,\" when in reality, it is \ncentered on 1. That difference is shown below.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nSIGMA <- 1 # this is our fixed and known standard deviation\nMU <- 1 # this is our true but unknown value\nMU_HAT <- 5 # this is our estimator\n\nggplot() + \n  \n  # plot the true distribution\n  stat_function(\n    fun = dnorm,\n    args = list(mean = MU, sd = SIGMA),\n    color = \"coral3\",\n    linewidth = 2\n  ) +\n  geom_vline(xintercept = MU, color = \"coral3\", size = 1) +\n  annotate(\n    geom = \"text\",\n    hjust = \"right\",\n    x = -.1,\n    y = .3,\n    label = latex2exp::TeX(\"$N(1, \\\\sigma^2)$\"),\n    color = \"coral3\"\n  ) +\n  \n  # plot the estimated distribution\n  stat_function(\n    fun = dnorm,\n    args = list(mean = MU_HAT, sd = SIGMA),\n    color = \"cyan4\",\n    linewidth = 2\n  ) +\n  geom_vline(xintercept = MU_HAT, color = \"cyan4\", size = 1) +\n  annotate(\n    geom = \"text\",\n    hjust = \"right\",\n    x = 6.8,\n    y = .3,\n    label = latex2exp::TeX(\"$N(5, \\\\sigma^2)$\"),\n    color = \"cyan4\"\n  ) +\n  \n  # annotation arrow\n  annotate(\n    geom = \"segment\",\n    x = MU,\n    xend = MU_HAT,\n    y = .19,\n    yend = .19,\n    arrow = arrow(length = unit(0.3, \"cm\"), ends = \"both\", type = \"closed\")\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 3,\n    y = 0.2,\n    label = \"bias\",\n    fontface = \"bold\"\n  ) +\n  \n  # aesthetic fixes\n  theme_minimal() +\n  labs(x = latex2exp::TeX(\"\\\\mu\")) +\n  scale_x_continuous(limits = c(-2, 8), breaks = -3:8) +\n  theme(\n    axis.title.y = element_blank(),\n    axis.line.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.line.x = element_line()\n  )\n```\n\n::: {.cell-output-display}\n![](math_stat_2_files/figure-html/visualize-bias-1.png){fig-align='center' width=672}\n:::\n:::\n\n\n\n\nAs we can see, the smaller our bias, the closer our guess becomes to the true \nvalue of our parameter. We can also see that a bias of zero is ideal. But there \nis more to an estimator than bias. Let's move on to variance.\n\n## Worked example: variance\n\nFormally, the variance of an estimator is the expected value of the squared \nsampling deviations. But that explanation might not be conceptually helpful. So, \nlet's see an example.\n\nSay a city has a population of 1,000,000. We want to get the average height of \neveryone in town. So we sample 1,000 people, measure their height, and use some \nfunction to calculate an estimator. We have used the same two estimators so far, \n$\\delta_1 = \\overline{X}$ and $\\delta_2 = 5$, so we will continue with those.\n\nDepending on the height of everyone in our 1,000-person sample, we will get a \ndifferent $\\overline{X}$ each time we take a sample. If we take 100 samples of \n1,000 people per sample, we will (probably) arrive at 100 distinct values of \n$\\overline{X}$. But if we use 5 as our estimator (perhaps to mean 5 feet tall), \nthere will be no such variation in our estimator. \n\nThe measure of how much our estimator fluctuates as we take more and more \nsamples is a helpful, intuitive understanding of variance. Ideally, we want to \nhave as little variance as possible. We know our estimator has no variance if \nwe use a constant (a number is always just that number), but what about \n$\\overline{X}$? Let's calculate.\n\n$$\n\\begin{align*}\nVar[\\delta_1(\\mathbf{X})|\\mu] &= Var(\\overline{X}) \\\\\n&= Var\\left[\\frac{1}{n}\\sum_{i=1}^nX_i\\right]\n& \\text{expanding out } \\overline{X} \\\\\n&= \\frac{1}{n^2}\\sum_{i=1}^nVar(X_i) \n& \\text{must square constants when factoring out of variance} \\\\\n&= \\frac{1}{n^2}\\sum_{i=1}^n\\sigma^2\n& Var(X_i) = \\sigma^2 \\text{ is fixed and known} \\\\\n&= \\frac{n\\sigma^2}{n^2} \\\\\n&= \\frac{\\sigma^2}{n}\n\\end{align*}\n$$\n\nNotice that this value is a positive number, which means the variance of \n$\\delta_1 = \\overline{X}$ is higher than the variance of $\\delta_2 = 5$, which \nis zero. \n\n## The Tradeoff\n\nThis phenomenon, where one estimator has better bias and the other has better \nvariance, is an example of a central balancing act that statisticians have to \nperform: the **bias-variance tradeoff**. We have seen an estimator with no \nbias but positive variance ($\\overline{X}$) and another with no variance but \nnon-zero bias (5). How do we know which is better? We will explore that question \nin the following article when we explore this tradeoff more deeply.\n\n# Conclusion\n\nWe are making steady progress, but we have much learning ahead! If you have any \nquestions or suggestions, you can always pop into my \n[Discord server](https://discord.gg/vF6W2bdKFH) and ask me directly. If you find \nany value in this work and want to support me financially, you can \n[buy me a coffee](https://buymeacoffee.com/mitchellharrison). Thank you for \nreading, and see you next time!",
    "supporting": [
      "math_stat_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}