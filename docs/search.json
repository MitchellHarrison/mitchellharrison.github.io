[
  {
    "objectID": "tutorials/math_stat_0.html",
    "href": "tutorials/math_stat_0.html",
    "title": "Hello, statistics. | Mathematical Statistics 0",
    "section": "",
    "text": "Background\nI recently finished STA 432 at Duke. For my fellow Duke students looking to take it: yes, it was that hard. But you’re smarter than me, so you will be fine! For the mathematically curious, the course is (somewhat longwindedly) called “Theory and Methods of Statistical Learning and Inference.” If, like me, you prefer helpful course names, call it “Mathematical Statistics.”\nWhile in STA 432, I kept finding myself in mathematics far beyond the “Google the topic and find it on 100 websites” stage. In fact, the topics covered in the course were typically covered by sources that assumed a level of mathematical maturity that I did not possess. I kept thinking that I needed to pre-understand the material to understand the explanation of that same material. I longed for a plain-language introduction to mathematically rigorous subjects.\nThis series is my humble attempt to communicate the beauty of mathematical statistics in comprehensible English to my fellow students (at Duke or at home). To facilitate this, we will take a “trust my word for it” approach, with proofs being in separate articles. However, I recommend at least reading through any proofs that I post. Struggling through those should prepare you for problems involving those same concepts. Even in the proofs articles, I’ll go step-by-step (very granularly) for easy comprehension. That is not a luxury that professors get in a short lecture period, but I’ll take my time to make sure every step is annotated, which I wish I had when I was in 432.\n\n\nCourse Outline\nThis course is broadly broken into three sections. First, we will study point estimators. If you’ve never heard of estimators, don’t worry. They’re just educated guesses at unknown distribution parameters (like the mean of a normal distribution). We will calculate estimators, study them, and choose between them.\nIn the middle portion of the course, we will look at confidence intervals. Again, no background knowledge is necessary here. In effect, confidence intervals tell us how confident we are that our chosen estimator falls into a particular range. Any statisticians reading just cringed at my description because it isn’t technically accurate, but we will discuss why that’s the case when we get to confidence intervals. Don’t worry; it’ll be pretty intuitive once we get there.\nLast but certainly not least, we will conduct hypothesis tests. There, we will choose two possible options for our estimator. For example, maybe we want to choose between X &gt; 5 or X &lt;= 5. We will use our data to decide which option is more likely to be correct. Of course, we will never be 100% of our guess, but we will get close.\nAnd that’s the course! It sounds nice and clean, and in many ways it is. However, like with much of statistics, the findings are the easy part. Finding the findings is the challenge. But I’ll try my best to get us through it so your GPA can be better than mine.\n\n\nCourse Materials\nMy course, which was run by Professor Alexander Volfovsky, had very few requirements. There was a recommended textbook (found here), which I found helpful to get a second perspective on topics. But if the price is off-putting, don’t worry. We only loosely followed it; apart from some homework questions, it was never explicitly required. So, for our purposes, I won’t reference the book directly. If you want a second perspective and don’t mind spending some coin, you have the Amazon link and can search the ISBN elsewhere.\nBesides that, you’ll only need a willingness to learn and a statistical curiosity!\n\n\nConclusion\nTo get started with the course, click here to go to the first article in the series, where we begin our discussion of estimators! Of course, if you want to ask me anything about this course, my time at Duke, or anything else, the best place to reach me is on Discord! And if you really want to support this project, you can buy me a coffee. Thank you for reading, and I can’t wait to get started!"
  },
  {
    "objectID": "tutorials/math_stat_3.html",
    "href": "tutorials/math_stat_3.html",
    "title": "Jensen’s Inequality | Mathematical Statistics 3",
    "section": "",
    "text": "Hello again! Last time, we found the bias and variance of two different estimators and discussed the bias-variance tradeoff. Now that we have some necessary background knowledge, let’s discuss balancing bias and variance to find a better estimator. Recall that we want our estimator to be accurate (have a small bias) and precise (have a small variance).\nWe mentioned the mean squared error (MSE) as a common way of analyzing an estimator. In the below equality, we only discussed the left-hand side. But now that we know what bias and variance are, we can observe a new (but equivalent) definition of the MSE:\n\\[\n\\mathbb{E}[(\\delta(\\mathbf{X}) - \\theta)^2] =\nVar[\\delta(\\mathbf{X}) | \\theta] + bias^2[\\delta(\\mathbf{X}) | \\theta].\n\\]\nThere, \\(\\mathbf{X}\\) is our data, \\(\\theta\\) is our unknown parameter, \\(\\delta(\\mathbf{X})\\) is our estimator, and \\(bias^2[\\cdot]\\) denotes our estimator’s bias squared."
  },
  {
    "objectID": "tutorials/math_stat_3.html#bias-example",
    "href": "tutorials/math_stat_3.html#bias-example",
    "title": "Jensen’s Inequality | Mathematical Statistics 3",
    "section": "Bias example",
    "text": "Bias example\nWe are scientists. We are confident that the machine in our lab is working, and it is spitting out data that comes from the following distribution:\n\\[\nX_1, \\cdots, X_n \\overset{\\mathrm{iid}}{\\sim} Exp(\\theta).\n\\]\nThe expected value (mean) of an exponential distribution is \\(\\mathbb{E}[X] = 1/ \\theta\\). We also know (or find on Wikipedia) that the probability density function (PDF) of an exponential is given by:\n\\[\nf_ \\theta(x) = \\theta e^{- \\theta x}.\n\\]\nOur goal is to study \\(\\theta\\). Let’s re-arrange the expected value of the exponential distribution to isolate \\(\\theta\\):\n\\[\\begin{align*}\n\\mathbb{E}[X] &= \\frac{1}{ \\theta} \\\\\n\\theta\\mathbb{E}[X] &= 1 \\\\\n\\theta &= \\frac{1}{\\mathbb{E}[X]}.\n\\end{align*}\\]\nNow that we have isolated \\(\\theta\\), we can start guessing at some estimators. Let’s replace \\(\\mathbb{E}[X]\\) with our sample mean (the average of whatever data we end up with). Like we did before, let’s call it \\(\\overline{X}\\). Then our first estimator will be \\[\n\\hat{\\theta}_1 = \\frac{1}{\\overline{X}}\n\\]\nLet’s see if our new estimator is unbiased. That is, if it has zero bias.\n\n\n\n\n\n\nDefinition\n\n\n\nJensen’s inequality: Let \\(g(\\cdot)\\) be a convex function (i.e., it has a positive second derivative). In that case, \\[\n\\mathbb{E}[g(X)] \\ge g(\\mathbb{E}[X])\n\\] with equality if \\(g\\) is linear.\n\n\nIn our case, \\(g(X) = \\hat{\\theta}_1\\). Therefore, Jensen’s inequality tells us that\n\\[\n\\mathbb{E}\\left[\\frac{1}{\\overline{X}}\\right] &gt; \\frac{1}{\\mathbb{E}[X]}.\n\\]\nWe noted earlier that the expected value of the exponential distribution that we are working with is \\(1/\\theta\\). Then,\n\\[\\begin{align*}\n\\mathbb{E}\\left[\\frac{1}{\\overline{X}}\\right]\n&&gt; \\frac{1}{\\mathbb{E}[X]} \\\\\n&&gt; \\frac{1}{\\frac{1}{\\theta}} \\\\\n&&gt; \\theta \\\\\n\\mathbb{E}[\\hat{\\theta}_1] &&gt; \\theta.\n\\end{align*}\\]\nSince the expected value of our estimator is not \\(\\theta\\), we have some non-zero bias. So, we know that our estimator is biased! Thanks for help Jensen.\nInstead of finding whether or not there is bias, we may want to calculate the exact bias of our estimator. For this example, doing so becomes quite the exercise in calculus and involves factoring constants out of integrals until those integrals evaluate to 1 (because we turn them into PDFs). Then we can safely get rid of them. But the math is such that it may be worth doing in a separate, smaller article. So for now, Jensen has at least showed us that our estimator is biased, and we will call that a win!"
  },
  {
    "objectID": "tutorials/tidytuesday_06112024.html",
    "href": "tutorials/tidytuesday_06112024.html",
    "title": "Campus Pride Index | TidyTutorial",
    "section": "",
    "text": "Introduction\nIn celebration of Pride Month, this week’s TidyTuesday provides data from the Campus Pride Index, which measures the safety and inclusivity of LGBTQ+ programs across universities in the United States.\nEach university is binned into one or more categories (e.g., military colleges, private/public, and others). What feels natural to me is to see how the Campus Pride Index compares across some of these categories. A proportionate stacked bar chart (where each bar has height equal to 1) is one option, but I would also like to see which types of universities are most common. If there are some categories with worse scores but with much smaller sample sizes, that would be helpful to know. So we’ll use a stacked bar, but not normalize the bar so we can also see how common each type is. Also bear in mind that a single university can (and often does) fall into multiple categories.\nLet’s set some global settings so I don’t have to worry about aspect ratio or other trivialities while we work.\n\n\nClick here for code\nknitr::opts_chunk$set(\n  fig.width = 10,        \n  fig.asp = 0.618,      # the golden ratio\n  fig.align = \"center\"  # center align figures\n)\n\n\n\n\nData Wrangling\nTime to load the data.\n\n\nClick here for code\nlibrary(tidyverse)\nlibrary(gglgbtq)\nlibrary(ggchicklet)\nlibrary(ggthemes)\nlibrary(DT)\n\n# load the data ----------------------------------------------------------------\n\npride_schools &lt;- read_csv(paste0(\n  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/\",\n  \"2024/2024-06-11/pride_index.csv\"\n))\n\npride_tags &lt;- read_csv(paste0(\n  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/\",\n  \"2024/2024-06-11/pride_index_tags.csv\"\n))\n\ndatatable(left_join(pride_schools, pride_tags))\n\n\n\n\n\n\nFirst, let’s format the data for ease of plotting. Right now, each category has its own column, with TRUE or NA values, where NA means “false” for our purposes. But we want the type of school to be represented in a single column so we can map that column to the color of the bars. To move multiple columns into a single one, we will pivot the data. Since we want to consolidate columns, we will need to make our data longer (i.e., add more rows), where each university now has multiple rows corresponding to TRUE or FALSE. Intuitively, to pivot the data longer, we use the pivot_longer function. Notice that once the pivot is complete, we only want to keep the rows where the value is TRUE, since the FALSE rows are just saying that “this university doesn’t fall into this type,” which is useless noise in our dataset.\n\n\nClick here for code\n# format data for plotting -----------------------------------------------------\n\nuni_types &lt;- pride_schools |&gt;\n  \n  # join both datasets into one\n  left_join(pride_tags) |&gt;\n  \n  # select which columns we want to analyze along with their ratings\n  select(rating, public, private, community, liberal_arts, technical,\n         religious, military, hbcu, hispanic_serving, aapi_serving,\n         other_minority_serving) |&gt; \n  \n  # replace NA with FALSE\n  mutate(across(everything(), ~ replace_na(., FALSE))) |&gt;\n  \n  # do the pivot\n  pivot_longer(cols = !rating, names_to = \"type\") |&gt;\n  \n  # drop the rows that don't apply\n  filter(value == TRUE) |&gt;\n  \n  # clean up some strings for prettier plotting\n  mutate(\n    type = str_replace_all(type, \"_\", \" \"),\n    type = str_to_title(type),\n    type = str_replace(type, \"Aapi\", \"AAPI\")\n  )\n\ndatatable(uni_types)\n\n\n\n\n\n\nThat looks just like we wanted it to. Now that our data is formatting, we can work on the plot. Per the data dictionary on the TidyVerse GitHub repository, we know that fractional scores are possible. A quick call to the unique function told me that the “fractional” scores are only half-stars, not any decimal in between two scores. So 1 and 1.5 are possible scores, but 1.7 is not. We should bin these scores by their leading digit so we have five possible fill values instead of ten. We’ll call these bins rating_levs, or “rating levels.”\nI would also like to order the bars in descending order of the total number of universities of that type. To do that, we’ll count how many of each category there are and save the order as a vector uni_levs, or “university levels.”\n\n\nClick here for code\nuni_levs &lt;- uni_types |&gt;\n  group_by(type) |&gt;\n  summarise(count = n()) |&gt;\n  arrange(desc(count)) |&gt;\n  pull(type)\n\nrating_levs &lt;- c(\"1 - 1.5\", \"2 - 2.5\", \"3 - 3.5\", \"4 - 4.5\", \"5\")\n\n\nFor our last data wrangling step, we can assign the rating bins to their respective ratings. I’ll create a new column for this and call it score. After that, we can group by type of university and score, and count the number of occurrences of each group. Then, we’ll be ready to plot.\n\n\nClick here for code\nuni_types &lt;- uni_types |&gt;\n  \n  # assign bins to the score variable\n  mutate(\n    score = case_when(\n      rating &lt; 2 ~ rating_levs[1],\n      rating &lt; 3 ~ rating_levs[2],\n      rating &lt; 4 ~ rating_levs[3],\n      rating &lt; 5 ~ rating_levs[4],\n      TRUE ~ rating_levs[5] \n    ),\n    \n    # order the score bins using the rating_levs we made earlier\n    score = factor(score, levels = rating_levs)\n  ) |&gt;\n  \n  # count the number of each type/score combination\n  group_by(type, score) |&gt;\n  summarise(count = n(), .groups = \"drop\") |&gt;\n  \n  # reorder the universities by descending order of number\n  mutate(type = factor(type, levels = rev(uni_levs)))\n\n\n\n\nThe Plot\nNow that we have our data, let’s get the skeleton of the plot going. I’m going to use a favorite “cheat code” of mine for making aesthetically pleasing bar graphs in R: the ggchicklet package. It lets us round the corners of each bar, which gives a much more aesthetic appearance (in my opinion). So, instead of using the geom_col function that is standard, we will use geom_chicklet instead.\nOne small note for geom_chicklet: it prefers to have bar graphs be vertical. But because my category names are long (and you never want to rotate text), I would like the plot to be horizontal. So I’ll map the type to the x axis and the counts to the y axis like geom_chicklet prefers, but I’ll use coord_flip afterwards to make it horizontal. This is the same technique that the author of the ggchicklet package uses in his demo on the ggchicklet GitHub repository.\n\n\nClick here for code\nuni_types |&gt;\n  ggplot(aes(x = type, y = count, fill = score)) +\n  geom_chicklet(position = position_stack(reverse = TRUE), width = 0.6) +\n  coord_flip()\n\n\n\n\n\n\n\n\n\nThis is already a great start! We have some aesthetic changes to make, but our bins and bars are in the order that we were hoping. Let’s change some colors.\nFirst, I’ll use my favorite theme function, which comes from the ggthemes package. That theme is theme_fivethirtyeight, which takes its name from the legendary data visualizations of the FiveThirtyEight website.\nI also think it would be appropriate for us to use Pride colors, don’t you? Of course, there is an R package for that: the gglgbtq package, which I imported earlier. We will use the “rainbow” color palette provided by gglgbtq to color our bars.\n\n\nClick here for code\nuni_types |&gt;\n  ggplot(aes(x = type, y = count, fill = score)) +\n  geom_chicklet(position = position_stack(reverse = TRUE), width = 0.6) +\n  coord_flip() +\n  \n  # change theme and base font size\n  theme_fivethirtyeight() +\n  \n  # change bar colors and put the legend in the right order\n  scale_fill_manual(values = palette_lgbtq(\"rainbow\"))\n\n\n\n\n\n\n\n\n\nNow we’re cooking! I think we are safe to add the title and subtitle, and then we can make a few more aesthetic changes before wrapping up. I want the background to be black (personal preference), which means the text needs to be white. I also don’t think that horizontal grid lines are necessary when the y axis is discrete, so we will remove those. I love the legend, but I would like it to be stacked and placed vertically in the plot, rather than horizontal and below the plot.\n\n\nClick here for code\nuni_types |&gt;\n  ggplot(aes(x = type, y = count, fill = score)) +\n  geom_chicklet(position = position_stack(reverse = TRUE), width = 0.6) +\n  coord_flip() +\n  theme_fivethirtyeight() +\n  scale_fill_manual(values = palette_lgbtq(\"rainbow\")) +\n  \n  # add title and subtitle\n  labs(\n    title = \"Campus Pride Index Scores\",\n    subtitle = \"Higher scores mean increased LGBTQ-inclusive policies/programs\",\n  ) +\n  \n  theme(\n    # make all text white\n    text = element_text(color = \"white\", family = \"Lato\") ,\n    \n    # adjust title font size\n    plot.title = element_text(),\n    \n    # make background black\n    plot.background = element_rect(fill = \"black\"),\n    panel.background = element_rect(fill = \"black\"),\n    legend.background = element_rect(fill = \"black\"),\n    \n    # remove grid lines\n    panel.grid.major.y = element_blank(),\n    \n    # move legend\n    legend.direction = \"vertical\",\n    legend.position = c(0.9, 0.5),\n  )\n\n\n\n\n\n\n\n\n\nMuch better! Only a few small edits left. First, I don’t think the legend needs a title. I also want the higher scores to be higher on the legend, so we can reverse the order of the legend inside of the scale_fill_manual function. The y axis text is a little far from the axis for my liking, so we will shift that in, and we’ll be done, save for one more thing: fonts.\nI’m going to use custom fonts that aren’t shipped with R or ggplot. These fonts come from Google Fonts, and we will need to use two packages to get them to work: sysfonts to load fonts from Google and showtext to get them to work with our plots. Once we import them, we can use them like any other font in our ggplot graphs!\n\n\nClick here for code\n# load fonts from Google Fonts into our project\nsysfonts::font_add_google(name = \"Galada\")\nsysfonts::font_add_google(name = \"Lato\")\nshowtext::showtext_auto()\n\nuni_types |&gt;\n  ggplot(aes(x = type, y = count, fill = score)) +\n  geom_chicklet(position = position_stack(reverse = TRUE), width = 0.6) +\n  coord_flip() +\n  theme_fivethirtyeight() +\n  scale_fill_manual(\n    values = palette_lgbtq(\"rainbow\"),\n    guide = guide_legend(reverse = TRUE) # reverse the legend order\n  ) +\n  labs(\n    title = \"Campus Pride Index Scores\",\n    subtitle = \"Higher scores mean increased LGBTQ-inclusive policies/programs\",\n  ) +\n  theme(\n    # use Lato font from Google for all text\n    text = element_text(color = \"white\", family = \"Lato\") ,\n    \n    # use Galada font from Google just for the title\n    plot.title = element_text(family = \"Galada\"),\n    \n    plot.background = element_rect(fill = \"black\"),\n    panel.background = element_rect(fill = \"black\"),\n    panel.grid.major.y = element_blank(),\n    legend.background = element_rect(fill = \"black\"),\n    legend.title = element_blank(),\n    legend.direction = \"vertical\",\n    legend.position = c(0.9, 0.5),\n    \n    # shift y axis text closer to the margin\n    axis.text.y = element_text(margin = margin(r = -20))\n  )\n\n\n\n\n\n\n\n\n\n\n\nConclusion\nDone! With some data wrangling and some nice themes, we have arrived of a graph that we can be proud of (get it?). I hope this helps you in your own data viz journey, but if you have further questions, feel free to join my Discord server and ask me personally! And if you are feeling grateful for my work (and are financially able to), you can give me a special thanks by buying me a coffee.\nAs always, thanks for reading, and see you next week!"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Here is a place to browse my tutorials! Feel free to browse or sort by category on the right side of the page. If you have any questions or ideas for new topics, let me know on Discord!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur World in Emissions | TidyTutorial\n\n\n\nData Viz\n\n\n\n\n\n\n\nMitch Harrison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCampus Pride Index | TidyTutorial\n\n\n\nData Viz\n\n\n\n\n\n\n\nMitch Harrison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Bias-Variance Tradeoff | Mathematical Statistics 2\n\n\n\nStatistics\n\n\nMathematical Statistics\n\n\n\n\n\n\n\nMitch Harrison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJensen’s Inequality | Mathematical Statistics 3\n\n\n\nStatistics\n\n\nMathematical Statistics\n\n\n\n\n\n\n\nMitch Harrison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to Estimators! | Mathematical Statistics 1\n\n\n\nStatistics\n\n\nMathematical Statistics\n\n\n\n\n\n\n\nMitch Harrison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello, statistics. | Mathematical Statistics 0\n\n\n\nStatistics\n\n\nMathematical Statistics\n\n\n\n\n\n\n\nMitch Harrison\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "These are my independent projects! They can be quick visualizations, full analyses with write-ups, and even interactive data exploration dashboards. Feel free to use the tags on the right side of the page to navigate, and reach out to me on Discord with any questions. Thanks!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Cheese Explorer | TidyTuesday\n\n\n\nData Viz\n\n\nTidyTuesday\n\n\nDashboard\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCampus Pride Index | TidyTuesday\n\n\n\nData Viz\n\n\nTidyTuesday\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOur World in Emissions | TidyTuesday\n\n\n\nData Viz\n\n\nTidyTuesday\n\n\n\n\n\n\n\nMitch Harrison\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/tidytuesday_06112024/pride.html",
    "href": "projects/tidytuesday_06112024/pride.html",
    "title": "Campus Pride Index | TidyTuesday",
    "section": "",
    "text": "Welcome!\nHappy pride month! On this fine TidyTuesday afternoon, we will see how different types of colleges and universities handle LGBTQ+ inclusion! The Campus Pride Index tracks safety, inclusivity, and LGBTQ+ policies/programs at universities across the United States. Results are on a 1-5 scale (with higher numbers being most inclusive), and colleges are grouped by various discrete categories. Today, we’ll build a stacked horizontal bar chart to see the distribution of scores for some of those categories. I’ll use the ggchicklet package and some custom fonts for easy aesthetic changes, and we’ll be done! If you want to see a step-by-step tutorial explaining the code, click here.\n\n\nClick here for code\nlibrary(tidyverse)\nlibrary(gglgbtq)\nlibrary(ggchicklet)\nlibrary(ggthemes)\n\n# load custom fonts for the plot -----------------------------------------------\n\nsysfonts::font_add_google(name = \"Galada\")\nsysfonts::font_add_google(name = \"Lato\")\nshowtext::showtext_auto()\n\n# load the data ----------------------------------------------------------------\n\npride_schools &lt;- read_csv(paste0(\n  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/\",\n  \"2024/2024-06-11/pride_index.csv\"\n))\n\npride_tags &lt;- read_csv(paste0(\n  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/\",\n  \"2024/2024-06-11/pride_index_tags.csv\"\n))\n\n# format data for plotting -----------------------------------------------------\n\nuni_types &lt;- pride_schools |&gt;\n  left_join(pride_tags) |&gt;\n  select(rating, public, private, community, liberal_arts, technical,\n         religious, military, hbcu, hispanic_serving, aapi_serving,\n         other_minority_serving) |&gt; \n  mutate(across(everything(), ~ replace_na(., FALSE))) |&gt;\n  pivot_longer(cols = !rating, names_to = \"type\") |&gt;\n  filter(value == TRUE) |&gt;\n  mutate(\n    type = str_replace_all(type, \"_\", \" \"),\n    type = str_to_title(type),\n    type = str_replace(type, \"Aapi\", \"AAPI\")\n  )\n\n# factor levels for ordering bars/fills ----------------------------------------\n\nuni_levs &lt;- uni_types |&gt;\n  group_by(type) |&gt;\n  summarise(count = n()) |&gt;\n  arrange(desc(count)) |&gt;\n  pull(type)\n\nrating_levs &lt;- c(\"1 - 1.5\", \"2 - 2.5\", \"3 - 3.5\", \"4 - 4.5\", \"5\")\n\n# build the plot! --------------------------------------------------------------\n\nuni_types |&gt;\n  mutate(\n    score = case_when(\n      rating &lt; 2 ~ rating_levs[1],\n      rating &lt; 3 ~ rating_levs[2],\n      rating &lt; 4 ~ rating_levs[3],\n      rating &lt; 5 ~ rating_levs[4],\n      TRUE ~ rating_levs[5] \n    ),\n    score = factor(score, levels = rating_levs)\n  ) |&gt;\n  group_by(type, score) |&gt;\n  summarise(count = n(), .groups = \"drop\") |&gt;\n  mutate(type = factor(type, levels = rev(uni_levs))) |&gt;\n  ggplot(aes(x = type, y = count, fill = score)) +\n  geom_chicklet(position = position_stack(reverse = TRUE), width = 0.6) +\n  coord_flip() +\n  theme_fivethirtyeight() +\n  scale_fill_manual(\n    values = palette_lgbtq(\"rainbow\"),\n    guide = guide_legend(reverse = TRUE)\n  ) +\n  labs(\n    title = \"Campus Pride Index Scores\",\n    subtitle = \"Higher scores mean increased LGBTQ-inclusive policies/programs\",\n  ) +\n  theme(\n    text = element_text(color = \"white\", family = \"Lato\") ,\n    plot.title = element_text(family = \"Galada\"),\n    plot.background = element_rect(fill = \"black\"),\n    panel.background = element_rect(fill = \"black\"),\n    panel.grid.major.y = element_blank(),\n    legend.background = element_rect(fill = \"black\"),\n    legend.title = element_blank(),\n    legend.direction = \"vertical\",\n    legend.position = c(0.9, 0.5),\n    axis.text.y = element_text(margin = margin(r = -20))\n  )\n\n\n\n\n\n\n\n\n\n\n\nConclusion\nThere we have it! Seeing very few 1s is a good sign, but there is always room for progress. The top three types of colleges by number (public, private, and liberal arts) are highly inclusive, while community colleges (where I started my educational journey) have a long way to go.\nIf you have any questions or suggestions for improvements, the best way to reach me is on Discord! And, of course, if you want to support this work financially, you can buy me a coffee!\nThanks for reading, and I’ll see you next week!"
  },
  {
    "objectID": "projects/tidytuesday_05212024/emissions.html",
    "href": "projects/tidytuesday_05212024/emissions.html",
    "title": "Our World in Emissions | TidyTuesday",
    "section": "",
    "text": "Hello, all! Welcome to TidyTuesday. This week, as climate analysts often do, we are going to get mildly depressing in pursuit of a pretty graph. This time, we will look at emissions from various actors’ coal, natural gas, and cement production. Spoiler: it’s not good.\nThe data for this week are brought to us by Carbon Majors, who have compiled a database going all the way back to the 1850’s! The dataset contains emission data for 75 state and non-state actors, but we will aggregate into total emissions by type for the plot. If you want to get more granular in your own plot, check out the data on the TidyTuesday GitHub repository here!\n\n\nClick here for code\nlibrary(tidyverse)\n\n# read data and rename an ugly column ------------------------------------------\nemis&lt;- read_csv(paste0(\n  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/\",\n  \"data/2024/2024-05-21/emissions.csv\"\n  )\n)\n\nemis &lt;- emis |&gt;\n  rename(emissions = \"total_emissions_MtCO2e\")\n\n# constants for ease of code legibility ----------------------------------------\nLEVS &lt;- c(\"Coal\", \"Oil & NGL\", \"Natural Gas\", \"Cement\")\nBG_COLOR &lt;- \"#F0F0F0\"\nGRAY &lt;- \"gray35\"\nUN_TEXT &lt;- paste(\n  \"In 1995, the United Nations\\nConference of the Parties met for\\nthe first\", \n  \"time to discuss the looming\\nthreat of climate change. The COP\\nhas\",\n  \"met twenty-eight times since.\"\n)\n\n# data cleanup -----------------------------------------------------------------\nemis |&gt;\n  filter(year &gt;= 1900) |&gt; # lots of near-zero space without this filter\n  mutate(\n    commodity = if_else(str_detect(commodity, \"Coal\"), \"Coal\", commodity),\n    commodity = factor(commodity, levels = LEVS) # re-order areas\n  ) |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9) +\n  \n  # UN COP annotation text box -------------------------------------------------\n  annotate(\n    geom = \"segment\",\n    x = 1995,\n    xend = 1995,\n    y = 35500,\n    yend = 20500,\n    linetype = \"solid\",\n    linejoin = \"round\",\n    linewidth = 1,\n    color = \"grey35\",\n    arrow = arrow(type = \"closed\", length = unit(0.2, \"cm\"))\n  ) +\n  annotate(\n    geom = \"rect\",\n    xmin = 1950.5,\n    xmax = 1993.5,\n    ymin = 23500,\n    ymax = 35800,\n    fill = BG_COLOR\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 1992,\n    y = 30000,\n    label = UN_TEXT,\n    color = GRAY,\n    fontface = \"italic\",\n    hjust = \"right\"\n  ) +\n  \n  # replace legend with annotation text ----------------------------------------\n  annotate(\n    geom = \"text\",\n    color = \"white\",\n    x = 2020,\n    y = c(1000, 4700, 13000, 26000),\n    label = c(\"Cement\", \"Natural Gas\", \"Oil & NGL\", \"Coal\"),\n    hjust = \"right\",\n    fontface = \"bold\"\n  ) +\n  \n  # visual style elements (love you, ggthemes) ---------------------------------\n  ggthemes::scale_fill_colorblind() +\n  ggthemes::theme_fivethirtyeight() +\n  \n  # customize axis breaks and labels -------------------------------------------\n  scale_x_continuous(breaks = seq(1900, 2020, 20)) +\n  scale_y_continuous(\n    breaks = seq(0, 40000, 5000), \n    label = scales::label_number(scale = 1e-3, suffix = \"k\")\n  ) +\n  labs(\n    x = element_blank(),\n    y = latex2exp::TeX(\"Emissions ($MtCO_2e$)\"),\n    title = \"Our World in Emissions\",\n    subtitle = latex2exp::TeX(\n      paste(\n        \"Emissions are measured in Millions of Tons of $CO_2$ equivalent\",\n        \"($MtCO_2e$)\"\n      )\n    ),\n    caption = paste(\n      \"Made with love by Mitch Harrison\",\n      \"                                                                       \",\n      \"Source: Carbon Majors database and TidyTuesday\"\n    )\n  ) + \n  \n  # theme cleanup --------------------------------------------------------------\n  geom_hline(yintercept = 0, linewidth = 0.7, color = GRAY) + # bold axis\n  theme(\n    legend.position = \"none\", # hide legend\n    axis.title.y = element_text(size = 10),\n    plot.background = element_rect(fill = BG_COLOR)\n  ) \n\n\n\n\n\n\n\n\n\nSo there she is! As we can see, the UN COP seems to be fighting an uphill battle. Emissions are rising, but a good analyst must note the limitations of the data. What jumps out to me is that renewables aren’t listed here because it’s only a graph of emissions. For all we know (from this graph), these emissions only produce a small portion of the world’s energy, and we are arguing about a couple of percentage points. Maybe we have defeated climate change after all!\nOf course, that’s not the case, but proving that point will require outside data. So, I welcome everyone reading to write a fuller report using more evidence. If nothing else, it would make for some fun data viz practice!\nIf you want a step-by-step guide to how I made this plot, there is a tutorial page here, or even stop by my Discord server and ask me! And, of course, if you appreciate my work enough to buy me a coffee, you can do so here. Thank you for reading, and see you next week!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi, I’m Mitch. 👋",
    "section": "",
    "text": "After leaving the Navy in 2022, I moved to North Carolina to study data science and political science at Duke University. Finishing my degree cost the military about $60,000 in aid and depleted my savings. Even my parents, who probably thought they could start spending their “put their kid through college” fund on fun things, had to chip in to help. My education was world-class but utterly unattainable for the majority of us. This website is my attempt to turn my course notes, homework, and projects into comprehensible articles for free. If nothing else, future Duke students struggling through their data science degree can look here for a different perspective.\nIf you want to see some of my analysis work, head to the Projects tab! If you are here to learn, the Tutorials tab is for you. Of course, if you are curious about the website’s structure, it is built with R and Quarto, and the code is available by clicking on the GitHub icon at the bottom-left of every page (or click here).\nAccess to information should always be free, so every article here is, and always will be, at no cost. If you want to show financial support, you can buy me a coffee! But I won’t ever make donor-exclusive educational content, so don’t feel like you’re missing out by not donating. It’s just one way to show thanks.\nI hope you enjoy the site, and feel free to reach out via GitHub issues to make suggestions for articles. Thanks for reading!"
  },
  {
    "objectID": "tutorials/tidytuesday_05212024.html",
    "href": "tutorials/tidytuesday_05212024.html",
    "title": "Our World in Emissions | TidyTutorial",
    "section": "",
    "text": "Welcome! If you saw my post for this week’s TidyTuesday, I’m glad you liked it enough to learn from it! If not, you can either scroll to the bottom to see the final product or click here. For this plot, we will use an area plot to visualize the global emissions by type going back to 1900. To start, we will use a bare-bones ggplot2 area chart with no bells or whistles to see what we are working with.\n\n\nClick here for code\nlibrary(tidyverse)\n\n# read data and rename an ugly column ------------------------------------------\nemis&lt;- read_csv(paste0(\n  \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/\",\n  \"data/2024/2024-05-21/emissions.csv\"\n  )\n)\n\nemis &lt;- emis |&gt;\n  rename(emissions = \"total_emissions_MtCO2e\")\n\nemis |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9)\n\n\n\n\n\n\n\n\n\nOkay, we’ve learned a lot. First, there are a lot of categories. A good rule of thumb is that once you get to about seven colors, even non-colorblind humans struggle to differentiate. But there is hope! Notice that there are several types of coal production. Let’s aggregate them. Second, there is a long tail on the left because of near-zero data. Let’s bring our limit to the right to get a better look.\n\n\nClick here for code\nemis |&gt;\n  filter(year &gt;= 1900) |&gt; # get rid of that tail\n  mutate(\n    # aggregate coal\n    commodity = if_else(str_detect(commodity, \"Coal\"), \"Coal\", commodity),\n  ) |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9)\n\n\n\n\n\n\n\n\n\nMuch better! But to me, having the smallest category (cement) on top feels awkward. Let’s reorder the categories! I’ll do so in descending order of emissions in the last year.\n\n\nClick here for code\nLEVS &lt;- c(\"Coal\", \"Oil & NGL\", \"Natural Gas\", \"Cement\") # our desired order\n\nemis |&gt;\n  filter(year &gt;= 1900) |&gt;\n  mutate(\n    commodity = if_else(str_detect(commodity, \"Coal\"), \"Coal\", commodity),\n    commodity = factor(commodity, levels = LEVS) # re-order \n  ) |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9)\n\n\n\n\n\n\n\n\n\nNow we’re cooking! It’s time for some style points. I’ll use my favorite aesthetic cheat code: ggthemes. Let’s add a theme and color scheme. I’m going with the FiveThirtyEight theme and a colorblind-friendly palette. I’ll also take this opportunity to adjust the opacity down just a touch. This is a personal choice, but I find it nice to be able to see the grid behind such ink-heavy plots as area plots.\n\n\n\n\n\n\nImportant\n\n\n\nRemember: unless you are making plots for a very small number of people and you know for certain that none are colorblind, making inaccessible plots is inexcusable. Of course, we all make mistakes, so if you ever notice an accessibility issue on my site, reach out and let me know on Discord or via a GitHub issue so I can improve for next time!\n\n\n\n\nClick here for code\nLEVS &lt;- c(\"Coal\", \"Oil & NGL\", \"Natural Gas\", \"Cement\") # our desired order\n\nemis |&gt;\n  filter(year &gt;= 1900) |&gt;\n  mutate(\n    commodity = if_else(str_detect(commodity, \"Coal\"), \"Coal\", commodity),\n    commodity = factor(commodity, levels = LEVS) # re-order \n  ) |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9) + # drop the opacity just a touch\n\n  # add theme and colors (love you, ggthemes) \n  ggthemes::scale_fill_colorblind() +\n  ggthemes::theme_fivethirtyeight()\n\n\n\n\n\n\n\n\n\nAnd just like that, it feels like we are almost there! Let’s change a few things at once. We will change the background color, add the title/subtitle/axis labels/caption, and format the \\(y\\)-axis to read 30k instead of 30000. That will give us a feel for the final color scheme and how the fonts feel on the page. Because of the subscript “2” in \\(CO_2\\), I will use the latex2exp package use \\(\\LaTeX\\) typesetting in the plot.\n\n\n\n\n\n\nNote\n\n\n\nOne note that is unique to this plot. When we use theme_fivethirtyeight, it removes the \\(y\\)-axis title. So, although we normally wouldn’t have to explicitly set the axis title to element_text in the theme function, we will here.\n\n\n\n\nClick here for code\nLEVS &lt;- c(\"Coal\", \"Oil & NGL\", \"Natural Gas\", \"Cement\")\nBG_COLOR &lt;- \"#F0F0F0\" # this will be our background color\n\nemis |&gt;\n  filter(year &gt;= 1900) |&gt;\n  mutate(\n    commodity = if_else(str_detect(commodity, \"Coal\"), \"Coal\", commodity),\n    commodity = factor(commodity, levels = LEVS) \n  ) |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9) +\n\n  ggthemes::scale_fill_colorblind() +\n  ggthemes::theme_fivethirtyeight() +\n\n  # abbreviate the y axis labels using the scales package\n  scale_y_continuous(label = scales::label_number(scale = 1e-3, suffix = \"k\")) +\n\n  # add labels to the plot -----------------------------------------------------\n  labs(\n    x = element_blank(),\n    y = latex2exp::TeX(\"Emissions ($MtCO_2e$)\"), # LaTeX typesetting with TeX()\n    title = \"Our World in Emissions\",\n    subtitle = latex2exp::TeX(\n      paste(\n        \"Emissions are measured in Millions of Tons of $CO_2$ equivalent\",\n        \"($MtCO_2e$)\"\n      )\n    ),\n    caption = paste(\n      \"Made with love by Mitch Harrison\",\n      # long blank line to \"hack\" a an annotation in the bottom-left corner\n      \"                                                                       \",\n      \"Source: Carbon Majors database and TidyTuesday\"\n    )\n  ) +\n  theme(\n    axis.title.y = element_text(size = 10),\n    plot.background = element_rect(fill = BG_COLOR) # change background color\n  ) \n\n\n\n\n\n\n\n\n\nYou could submit this plot for public consumption without shame, but we can do better! For example, I think we could safely remove the legend by annotating the colors directly on the plot. Let’s use a geom_text to do just that. While this entire process has been creative, we are getting into highly subjective territory here. So if you don’t like these changes, do something else! I would love to see your ideas.\nTo make the annotations, I want the text to be right-justified and directly atop one another. To accomplish that, I will give geom_text a single \\(x\\) value but several \\(y\\) values (one for each category).\n\n\nClick here for code\nLEVS &lt;- c(\"Coal\", \"Oil & NGL\", \"Natural Gas\", \"Cement\")\nBG_COLOR &lt;- \"#F0F0F0\"\n\nemis |&gt;\n  filter(year &gt;= 1900) |&gt;\n  mutate(\n    commodity = if_else(str_detect(commodity, \"Coal\"), \"Coal\", commodity),\n    commodity = factor(commodity, levels = LEVS) \n  ) |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9) +\n\n  ggthemes::scale_fill_colorblind() +\n  ggthemes::theme_fivethirtyeight() +\n  scale_y_continuous(label = scales::label_number(scale = 1e-3, suffix = \"k\")) +\n\n  # add annotation text to replace the legend ----------------------------------\n  annotate(\n    geom = \"text\",\n    color = \"white\",\n    x = 2020,\n    y = c(1000, 4700, 13000, 26000),\n    label = c(\"Cement\", \"Natural Gas\", \"Oil & NGL\", \"Coal\"),\n    hjust = \"right\",\n    fontface = \"bold\"\n  ) +\n\n  labs(\n    x = element_blank(),\n    y = latex2exp::TeX(\"Emissions ($MtCO_2e$)\"),\n    title = \"Our World in Emissions\",\n    subtitle = latex2exp::TeX(\n      paste(\n        \"Emissions are measured in Millions of Tons of $CO_2$ equivalent\",\n        \"($MtCO_2e$)\"\n      )\n    ),\n    caption = paste(\n      \"Made with love by Mitch Harrison\",\n      \"                                                                       \",\n      \"Source: Carbon Majors database and TidyTuesday\"\n    )\n  ) +\n\n  theme(\n    legend.position = \"none\", # hide the legend\n    axis.title.y = element_text(size = 10),\n    plot.background = element_rect(fill = BG_COLOR)\n  ) \n\n\n\n\n\n\n\n\n\nNailed it. Now, I will happily take criticism here. I don’t love that the “Cement” label isn’t entirely encompassed by its data. But I think it’s much cleaner than having a legend drawing our eye away from the plot, so I’ll keep it.\nThe last thing we have to do before we can worry about the big annotation in the middle of the plot is change where the axes break. That is, set the years and emission amount displayed on the x and y axes, respectively. And while I’m at it, I will use a geom_hline to make the \\(x\\)-axis a bit bolder since it melts into the background a little bit too much for my liking.\n\n\nClick here for code\nLEVS &lt;- c(\"Coal\", \"Oil & NGL\", \"Natural Gas\", \"Cement\")\nBG_COLOR &lt;- \"#F0F0F0\"\nGRAY &lt;- \"gray35\"\n\nemis |&gt;\n  filter(year &gt;= 1900) |&gt;\n  mutate(\n    commodity = if_else(str_detect(commodity, \"Coal\"), \"Coal\", commodity),\n    commodity = factor(commodity, levels = LEVS) \n  ) |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9) +\n\n  ggthemes::scale_fill_colorblind() +\n  ggthemes::theme_fivethirtyeight() +\n\n  # change where the axis breaks occur -----------------------------------------\n  scale_x_continuous(breaks = seq(1900, 2020, 20)) +\n  scale_y_continuous(\n    breaks = seq(0, 40000, 5000), \n    label = scales::label_number(scale = 1e-3, suffix = \"k\")\n  ) +\n\n  annotate(\n    geom = \"text\",\n    color = \"white\",\n    x = 2020,\n    y = c(1000, 4700, 13000, 26000),\n    label = c(\"Cement\", \"Natural Gas\", \"Oil & NGL\", \"Coal\"),\n    hjust = \"right\",\n    fontface = \"bold\"\n  ) +\n\n  labs(\n    x = element_blank(),\n    y = latex2exp::TeX(\"Emissions ($MtCO_2e$)\"),\n    title = \"Our World in Emissions\",\n    subtitle = latex2exp::TeX(\n      paste(\n        \"Emissions are measured in Millions of Tons of $CO_2$ equivalent\",\n        \"($MtCO_2e$)\"\n      )\n    ),\n    caption = paste(\n      \"Made with love by Mitch Harrison\",\n      \"                                                                       \",\n      \"Source: Carbon Majors database and TidyTuesday\"\n    )\n  ) +\n\n  geom_hline(yintercept = 0, linewidth = 0.7, color = GRAY) + # bold axis\n  theme(\n    legend.position = \"none\", # hide the legend\n    axis.title.y = element_text(size = 10),\n    plot.background = element_rect(fill = BG_COLOR)\n  ) \n\n\n\n\n\n\n\n\n\nOnce I write-in the line breaks, I’ll use the annotate function as before. But that’s not all. By default, there is no background with text annotations, so the grid overlaps the text and decreases legibility. To fix this, I’ll use annotate to put a rectangle the same color as the plot background behind the text, which “removes” the grid lines behind the text.\nFinally, to accomplish the arrow, we will use our final annotate to draw a line segment and put an arrowhead at the end.\n\n\n\n\n\n\nNote\n\n\n\nNormally, the order that we put things in a ggplot2 pipeline doesn’t matter. But here, if you put the background rectangle after the text annotation, it will cover the text, rendering it invisible.\n\n\nBecause this is our last edit, I will take this opportunity to make one very oft-forgotten change: write my alt text. Since you’re here, I know you respect the power of data communication. Alt text lets us communicate with those who sometimes miss out on learning from plots online. As our color palette did for colorblind viewers, we owe it to our non-sighted friends to let them participate.\nAnd finally, I’ll change the aspect ratio of the plot. You may have heard of the golden ratio, which is a ratio that many humans find inherently satisfying to look at. That ratio is approximately 1.618:1. The inverse of that number is 0.618, which will be our horizontal aspect ratio (1.618 is vertical). Because the quarto headers won’t render with the document, my final header is below:\n#| label: plt-final\n#| fig-width: 8\n#| fig-align: \"center\"\n#| fig-asp: 0.618\n#| fig-alt: |\n#|   This plot is titled Our World in Emissions. It is an area plot that shows\n#|   global emissions over time by type. The types are coal, natural gas,\n#|   cement, and oil and NGL. The plot notes that in 1995, the UN first met to\n#|   discuss the climate threat. The plot shows near-zero emissions from 1900 to\n#|   1920, when a slow increase begins. From there, emission growth seems to be\n#|   exponentially increasing, with no decline since the UN first met. Coal is\n#|   the largest emitter, then oil and NGL, then natural gas, and finally,\n#|   cement.\nNow, let’s see the plot!\n\n\nClick here for code\n# constants for ease of code legibility ----------------------------------------\nLEVS &lt;- c(\"Coal\", \"Oil & NGL\", \"Natural Gas\", \"Cement\")\nBG_COLOR &lt;- \"#F0F0F0\"\nUN_TEXT &lt;- paste(\n  \"In 1995, the United Nations\\nConference of the Parties met for\\nthe first\", \n  \"time to discuss the looming\\nthreat of climate change. The COP\\nhas\",\n  \"met twenty-eight times since.\"\n)\n\n# data cleanup -----------------------------------------------------------------\nemis |&gt;\n  filter(year &gt;= 1900) |&gt; # lots of near-zero space without this filter\n  mutate(\n    commodity = if_else(str_detect(commodity, \"Coal\"), \"Coal\", commodity),\n    commodity = factor(commodity, levels = LEVS) # re-order areas\n  ) |&gt;\n  group_by(year, commodity) |&gt;\n  summarise(emissions = sum(emissions), .groups = \"drop\") |&gt;\n  \n  # start of plot --------------------------------------------------------------\n  ggplot(aes(x = year, y = emissions, fill = commodity)) +\n  geom_area(alpha = 0.9) +\n  \n  # UN COP annotation text box -------------------------------------------------\n\n  # the arrow\n  annotate(\n    geom = \"segment\",\n    x = 1995,\n    xend = 1995,\n    y = 35500,\n    yend = 20500,\n    linetype = \"solid\",\n    linejoin = \"round\",\n    linewidth = 1,\n    color = \"grey35\",\n    arrow = arrow(type = \"closed\", length = unit(0.2, \"cm\"))\n  ) +\n\n  # the background rectangle (must be before the text)\n  annotate(\n    geom = \"rect\",\n    xmin = 1945.5,\n    xmax = 1993.5,\n    ymin = 23500,\n    ymax = 35800,\n    fill = BG_COLOR\n  ) +\n\n  # annotation text\n  annotate(\n    geom = \"text\",\n    x = 1992,\n    y = 30000,\n    label = UN_TEXT,\n    color = GRAY,\n    fontface = \"italic\",\n    hjust = \"right\"\n  ) +\n  \n  # replace legend with annotation text ----------------------------------------\n  annotate(\n    geom = \"text\",\n    color = \"white\",\n    x = 2020,\n    y = c(1000, 4700, 13000, 26000),\n    label = c(\"Cement\", \"Natural Gas\", \"Oil & NGL\", \"Coal\"),\n    hjust = \"right\",\n    fontface = \"bold\"\n  ) +\n  \n  # visual style elements (love you, ggthemes) ---------------------------------\n  ggthemes::scale_fill_colorblind() +\n  ggthemes::theme_fivethirtyeight() +\n  \n  # customize axis breaks and labels -------------------------------------------\n  scale_x_continuous(breaks = seq(1900, 2020, 20)) +\n  scale_y_continuous(\n    breaks = seq(0, 40000, 5000), \n    label = scales::label_number(scale = 1e-3, suffix = \"k\")\n  ) +\n  labs(\n    x = element_blank(),\n    y = latex2exp::TeX(\"Emissions ($MtCO_2e$)\"),\n    title = \"Our World in Emissions\",\n    subtitle = latex2exp::TeX(\n      paste(\n        \"Emissions are measured in Millions of Tons of $CO_2$ equivalent\",\n        \"($MtCO_2e$)\"\n      )\n    ),\n    caption = paste(\n      \"Made with love by Mitch Harrison\",\n      \"                                                                       \",\n      \"Source: Carbon Majors database and TidyTuesday\"\n    )\n  ) + \n  \n  # theme cleanup --------------------------------------------------------------\n  geom_hline(yintercept = 0, linewidth = 0.7, color = GRAY) + # bold axis\n  theme(\n    legend.position = \"none\", \n    axis.title.y = element_text(size = 10),\n    plot.background = element_rect(fill = BG_COLOR)\n  ) \n\n\n\n\n\n\n\n\n\nNo plot is perfect, but I am happy with what we have accomplished, and I hope you are too! If you have any questions or corrections, feel free to reach out on Discord, and I’ll be happy to help. And, of course, if you want to contribute to this effort financially, you are more than welcome to buy me a coffee.\nThanks for sticking around, and good luck with your TidyTuesday adventures!"
  },
  {
    "objectID": "tutorials/math_stat_2.html",
    "href": "tutorials/math_stat_2.html",
    "title": "The Bias-Variance Tradeoff | Mathematical Statistics 2",
    "section": "",
    "text": "Last time, we noted that we cannot precisely calculate bias or variance since they are conditional on the parameter we are estimating in the first place. If we knew that value, we wouldn’t need an estimator. Ideally, our estimators would be as close as possible to the true value of our unknown parameter \\(\\theta\\), but there may be infinitely many possible values for \\(\\theta\\). Instead, we will seek to be close to a range of possible values of \\(\\theta\\).\n\n\n\n\n\n\nDefinition\n\n\n\nCloseness describes how much we are willing to “pay” to be some “distance” away from the true value of \\(\\theta\\). We will measure this distance with a function (called a loss function), which is denoted as:\n\\[\n\\ell(\\theta, a).\n\\] This notation is somewhat confusing, because we are now using \\(a\\) to denote our estimate instead of \\(\\hat{\\theta}\\). So you can think of it as \\(\\ell(\\theta, \\hat{\\theta})\\) if that is more helpful (as it is for me).\n\n\nAs an example, if we choose a loss function,\n\\[\n\\ell(\\theta, \\hat{\\theta}) = (\\theta - \\hat{\\theta})^2,\n\\] then we have arrived at the squared-error loss function. Observe that the difference between our guess and the true value is the error, and we are squaring that value. If we take the mean of that function, we arrive at a critical value in mathematical statistics that you may have heard of: the mean-squared error (MSE).\n\n\n\n\n\n\nDefinition\n\n\n\nRisk is the expected loss for a given loss function \\(\\ell\\). Mathematically, it is denoted as \\[\nR_{\\delta}(\\theta) = \\mathbb{E}_{X|\\theta}[\\ell(\\theta, \\delta(\\mathbf{X}))],\n\\] where \\(\\delta(\\mathbf{X})\\) is the function that gives us our estimator. In effect, the risk is the expected loss given some loss function \\(\\ell(\\theta,\\hat{\\theta})\\).\n\n\nWe will get back to loss next time."
  },
  {
    "objectID": "tutorials/math_stat_2.html#worked-example-bias",
    "href": "tutorials/math_stat_2.html#worked-example-bias",
    "title": "The Bias-Variance Tradeoff | Mathematical Statistics 2",
    "section": "Worked example: bias",
    "text": "Worked example: bias\nLet’s work on our first example problem to nail some things down. Let our data \\(X_1, \\cdots, X_n \\sim N(\\mu, \\sigma^2)\\), and let each data point be independent and identically distributed (iid). Like last time, \\(\\sigma^2\\) is fixed and known. We are interested in estimating \\(\\mu\\). Recall our two estimators from the previous article:\n\\[\n\\begin{align*}\n\\delta_1(\\mathbf{X}) &= \\overline{X} \\\\\n\\delta_2(\\mathbf{X}) &= 5.\n\\end{align*}\n\\]\nThe expected value of \\(\\delta_2\\) is 5. Let’s find the expected value of \\(\\delta_1\\). Recall our generic formula for the expectation of an estimator is \\(\\mathbb{E}(\\delta(\\mathbf{X}) | \\theta)\\) for some estimator \\(\\delta\\) and true value \\(\\theta\\). In this case, our estimator is \\(\\overline{X}\\) and our parameter is \\(\\mu\\). Thus: \\[\n\\begin{align*}\n\\mathbb{E}(\\delta_1(\\mathbf{X})|\\theta) &= \\mathbb{E}(\\overline{X} | \\mu) \\\\\n&= \\mathbb{E}\\left[\\frac{\\sum_{i=1}^nX_i}{n}\\right]\n& \\text{expanding out }\\overline{X} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mathbb{E}(X_i|\\mu)\n& \\text{expectation can be distributed into sums} \\\\\n&= \\frac{1}{n}\\sum_{i=1}^n\\mu\n& \\text{because } \\mathbb{E}(X_i) = \\mu \\text{ for any }i\\\\\n&= \\frac{n\\mu}{n} \\\\\n&= \\mu\n\\end{align*}\n\\]\nWe have a bias of zero! That means that the expected value of our estimator is precisely equivalent to our unknown parameter. It feels like we have solved statistics, right? Well… no. But we will get to that in a moment. For now, let’s visualize bias.\nLet’s say that the true (but unknown to us) value of \\(\\mu\\) is 1. One of our estimators was the constant 5. If we let 5 be our guess for the mean, we are saying, “I think the distribution is centered on 5,” when in reality, it is centered on 1. That difference is shown below.\n\n\nClick here for code\nlibrary(tidyverse)\n\nSIGMA &lt;- 1 # this is our fixed and known standard deviation\nMU &lt;- 1 # this is our true but unknown value\nMU_HAT &lt;- 5 # this is our estimator\n\nggplot() + \n  \n  # plot the true distribution\n  stat_function(\n    fun = dnorm,\n    args = list(mean = MU, sd = SIGMA),\n    color = \"coral3\",\n    linewidth = 2\n  ) +\n  geom_vline(xintercept = MU, color = \"coral3\", size = 1) +\n  annotate(\n    geom = \"text\",\n    hjust = \"right\",\n    x = -.1,\n    y = .3,\n    label = latex2exp::TeX(\"$N(1, \\\\sigma^2)$\"),\n    color = \"coral3\"\n  ) +\n  \n  # plot the estimated distribution\n  stat_function(\n    fun = dnorm,\n    args = list(mean = MU_HAT, sd = SIGMA),\n    color = \"cyan4\",\n    linewidth = 2\n  ) +\n  geom_vline(xintercept = MU_HAT, color = \"cyan4\", size = 1) +\n  annotate(\n    geom = \"text\",\n    hjust = \"right\",\n    x = 6.8,\n    y = .3,\n    label = latex2exp::TeX(\"$N(5, \\\\sigma^2)$\"),\n    color = \"cyan4\"\n  ) +\n  \n  # annotation arrow\n  annotate(\n    geom = \"segment\",\n    x = MU,\n    xend = MU_HAT,\n    y = .19,\n    yend = .19,\n    arrow = arrow(length = unit(0.3, \"cm\"), ends = \"both\", type = \"closed\")\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 3,\n    y = 0.2,\n    label = \"bias\",\n    fontface = \"bold\"\n  ) +\n  \n  # aesthetic fixes\n  theme_minimal() +\n  labs(x = latex2exp::TeX(\"\\\\mu\")) +\n  scale_x_continuous(limits = c(-2, 8), breaks = -3:8) +\n  theme(\n    axis.title.y = element_blank(),\n    axis.line.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    axis.line.x = element_line()\n  )\n\n\n\n\n\n\n\n\n\nAs we can see, the smaller our bias, the closer our guess becomes to the true value of our parameter. We can also see that a bias of zero is ideal. But there is more to an estimator than bias. Let’s move on to variance."
  },
  {
    "objectID": "tutorials/math_stat_2.html#worked-example-variance",
    "href": "tutorials/math_stat_2.html#worked-example-variance",
    "title": "The Bias-Variance Tradeoff | Mathematical Statistics 2",
    "section": "Worked example: variance",
    "text": "Worked example: variance\nFormally, the variance of an estimator is the expected value of the squared sampling deviations. But that explanation might not be conceptually helpful. So, let’s see an example.\nSay a city has a population of 1,000,000. We want to get the average height of everyone in town. So we sample 1,000 people, measure their height, and use some function to calculate an estimator. We have used the same two estimators so far, \\(\\delta_1 = \\overline{X}\\) and \\(\\delta_2 = 5\\), so we will continue with those.\nDepending on the height of everyone in our 1,000-person sample, we will get a different \\(\\overline{X}\\) each time we take a sample. If we take 100 samples of 1,000 people per sample, we will (probably) arrive at 100 distinct values of \\(\\overline{X}\\). But if we use 5 as our estimator (perhaps to mean 5 feet tall), there will be no such variation in our estimator.\nThe measure of how much our estimator fluctuates as we take more and more samples is a helpful, intuitive understanding of variance. Ideally, we want to have as little variance as possible. We know our estimator has no variance if we use a constant (a number is always just that number), but what about \\(\\overline{X}\\)? Let’s calculate.\n\\[\n\\begin{align*}\nVar[\\delta_1(\\mathbf{X})|\\mu] &= Var(\\overline{X}) \\\\\n&= Var\\left[\\frac{1}{n}\\sum_{i=1}^nX_i\\right]\n& \\text{expanding out } \\overline{X} \\\\\n&= \\frac{1}{n^2}\\sum_{i=1}^nVar(X_i)\n& \\text{must square constants when factoring out of variance} \\\\\n&= \\frac{1}{n^2}\\sum_{i=1}^n\\sigma^2\n& Var(X_i) = \\sigma^2 \\text{ is fixed and known} \\\\\n&= \\frac{n\\sigma^2}{n^2} \\\\\n&= \\frac{\\sigma^2}{n}\n\\end{align*}\n\\]\nNotice that this value is a positive number, which means the variance of \\(\\delta_1 = \\overline{X}\\) is higher than the variance of \\(\\delta_2 = 5\\), which is zero."
  },
  {
    "objectID": "tutorials/math_stat_2.html#the-tradeoff",
    "href": "tutorials/math_stat_2.html#the-tradeoff",
    "title": "The Bias-Variance Tradeoff | Mathematical Statistics 2",
    "section": "The Tradeoff",
    "text": "The Tradeoff\nThis phenomenon, where one estimator has better bias and the other has better variance, is an example of a central balancing act that statisticians have to perform: the bias-variance tradeoff. We have seen an estimator with no bias but positive variance (\\(\\overline{X}\\)) and another with no variance but non-zero bias (5). How do we know which is better? We will explore that question in the following article when we explore this tradeoff more deeply."
  },
  {
    "objectID": "tutorials/math_stat_1.html",
    "href": "tutorials/math_stat_1.html",
    "title": "Welcome to Estimators! | Mathematical Statistics 1",
    "section": "",
    "text": "Say we have some data \\(\\mathbf{X}\\). It’s a vector, so just think of it like a list of \\(n\\) numbers. We want to learn something about how these data came to be. First, we will aggregate our data using a statistic.\n\n\n\n\n\n\nDefinition\n\n\n\nLet \\(X_1, \\cdots, X_n\\) be our data. A statistic is a function of that data. We will denote that statistic with \\(\\delta\\). Crucially, this function cannot contain anything that we don’t know. It is purely a function of known quantities.\n\n\n\n\nLet’s say that our data comes from a normal distribution (a “bell curve”). We denote this with \\(X \\sim N(\\mu, \\sigma^2)\\), where \\(\\mu\\) is the mean of the distribution and \\(\\sigma^2\\) is the variance. Also, to make our life easier, say we know the variance \\(\\sigma^2\\). In practice, this will basically never be the case, but it will simplify our math for now.\nWe have infinitely many options for statistics that we can choose. For example, we could use \\(X_1\\) (that is, the first data point in our vector). While we leave some data on the table in that case, it is certainly a statistic since \\(\\delta = X_1\\) is a function of our data, and there are no unknowns.\nAlternatively, we could use the observed mean of our data. We will call it \\(\\overline{X}\\) (pronounced “\\(X\\) bar”), and it is denoted with \\[\n\\delta(\\mathbf{X}) = \\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nNotice that this is also a statistic! Although it looks much more complicated, we are still using our data and no unknowns. Here, \\(n\\) is the number of data points that we have, which we know. And we know every \\(X_i\\) because each is part of our data vector \\(\\mathbf{X}\\).\n\n\n\n\n\n\nNote\n\n\n\nConstants (e.g., 7) are also statistics, although no data are involved in the calculation. If it feels like you’re just guessing at random if you do this, you’re right.\n\n\nNow let’s look at an example of a function that is not a statistic: \\[\n\\delta(\\mathbf{X}) = T = \\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}}.\n\\] This function will come back in future articles, but for now, recall that we said that we already know the variance \\(\\sigma^2\\). So that means we already know \\(\\sigma\\). We also know \\(n\\), as we mentioned earlier. But \\(\\mu\\) is unknown to us. Because we have an unknown value \\(\\mu\\) in the numerator, \\(T\\) is not a statistic."
  },
  {
    "objectID": "tutorials/math_stat_1.html#statistics",
    "href": "tutorials/math_stat_1.html#statistics",
    "title": "Welcome to Estimators! | Mathematical Statistics 1",
    "section": "",
    "text": "Let’s say that our data comes from a normal distribution (a “bell curve”). We denote this with \\(X \\sim N(\\mu, \\sigma^2)\\), where \\(\\mu\\) is the mean of the distribution and \\(\\sigma^2\\) is the variance. Also, to make our life easier, say we know the variance \\(\\sigma^2\\). In practice, this will basically never be the case, but it will simplify our math for now.\nWe have infinitely many options for statistics that we can choose. For example, we could use \\(X_1\\) (that is, the first data point in our vector). While we leave some data on the table in that case, it is certainly a statistic since \\(\\delta = X_1\\) is a function of our data, and there are no unknowns.\nAlternatively, we could use the observed mean of our data. We will call it \\(\\overline{X}\\) (pronounced “\\(X\\) bar”), and it is denoted with \\[\n\\delta(\\mathbf{X}) = \\overline{X} = \\frac{1}{n}\\sum_{i=1}^n X_i.\n\\]\nNotice that this is also a statistic! Although it looks much more complicated, we are still using our data and no unknowns. Here, \\(n\\) is the number of data points that we have, which we know. And we know every \\(X_i\\) because each is part of our data vector \\(\\mathbf{X}\\).\n\n\n\n\n\n\nNote\n\n\n\nConstants (e.g., 7) are also statistics, although no data are involved in the calculation. If it feels like you’re just guessing at random if you do this, you’re right.\n\n\nNow let’s look at an example of a function that is not a statistic: \\[\n\\delta(\\mathbf{X}) = T = \\frac{\\overline{X} - \\mu}{\\sigma/\\sqrt{n}}.\n\\] This function will come back in future articles, but for now, recall that we said that we already know the variance \\(\\sigma^2\\). So that means we already know \\(\\sigma\\). We also know \\(n\\), as we mentioned earlier. But \\(\\mu\\) is unknown to us. Because we have an unknown value \\(\\mu\\) in the numerator, \\(T\\) is not a statistic."
  },
  {
    "objectID": "tutorials/math_stat_1.html#point-estimator-example",
    "href": "tutorials/math_stat_1.html#point-estimator-example",
    "title": "Welcome to Estimators! | Mathematical Statistics 1",
    "section": "Point estimator example",
    "text": "Point estimator example\nLet’s keep going with our data, which comes from a normal distribution. But, to get used to using \\(\\theta\\), say that \\(X \\sim N(\\theta, \\sigma^2)\\). One possible estimator is the example mean \\(\\overline{X}\\) from earlier (i.e., the mean of the observed data). Alternatively, we can use a constant: say 5. Intuitively, it feels like \\(\\hat{\\theta} = \\overline{X}\\) would be a better guess than a simple \\(\\hat{\\theta} = 5\\), because it is actually informed by the data. But how do we quantify that intuition? We will calculate and compare both bias and precision for each.\n\nBias\nBias tells us how often, on average, we get the correct value of our unknown parameter \\(\\theta\\). Mathematically, we hope that the following quantity is as small as possible: \\[\n\\mathbb{E}[\\delta(\\mathbf{X}) | \\theta] - \\theta.\n\\]\nThe confusing-looking term \\(\\mathbb{E}[\\cdot]\\) is the expected value of our estimator, given the value of the unknown parameter \\(\\theta\\). Basically, this is the expected value of \\(\\hat{\\theta}\\). If our estimator \\(\\hat{\\theta}\\) is expected to be exactly correct on average, then this whole term will be 0, which is the smallest possible bias.\n\n\nVariance\nVariance describes the variability of our estimator. Ideally, variance is also small. Intuitively we are less “sure” about our estimate if we have a wider variance. We denote variance with \\(Var(\\delta(\\mathbf{X})|\\theta)\\).\nHowever, notice that both bias and variance are conditional on the true value of our unknown parameter \\(\\theta\\). Thus, we cannot calculate these quantities directly. To deal with this, we will introduce the concept of loss in the next article here!"
  }
]